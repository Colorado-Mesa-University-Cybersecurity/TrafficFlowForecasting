{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gotta get those dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import fastai\n",
    "\n",
    "\n",
    "from datetime import (\n",
    "    datetime\n",
    ")\n",
    "\n",
    "from sklearn.preprocessing import (\n",
    "    StandardScaler\n",
    ")\n",
    "\n",
    "from fastai.tabular.all import (\n",
    "    LinBnDrop\n",
    ")\n",
    "\n",
    "from fastai.layers import (\n",
    "    Identity\n",
    ")\n",
    "\n",
    "from fastai.metrics import (\n",
    "    BalancedAccuracy,\n",
    "    F1Score,\n",
    "    MatthewsCorrCoef,\n",
    "    Precision,\n",
    "    Recall,\n",
    "    RocAuc\n",
    ")\n",
    "\n",
    "from typing import (\n",
    "    Callable,\n",
    "    Dict,\n",
    "    List,\n",
    "    Tuple\n",
    ")\n",
    "\n",
    "from Quick.cleaning.loading import (\n",
    "    examine_dataset,\n",
    "    remove_infs_and_nans\n",
    ")\n",
    "\n",
    "from Quick.cleaning.utils import (\n",
    "    get_file_path\n",
    ")\n",
    "\n",
    "from Quick.runners.deep import (\n",
    "    run_deep_nn_experiment\n",
    ")\n",
    "\n",
    "from Quick.runners.residual import (\n",
    "    run_residual_deep_nn_experiment\n",
    ")\n",
    "\n",
    "from Quick.runners.sk import (\n",
    "    run_sk_experiment\n",
    ")\n",
    "\n",
    "from Quick.runners.torch import (\n",
    "    run_torch_nn_experiment\n",
    ")\n",
    "\n",
    "from rff.layers import (\n",
    "    GaussianEncoding,\n",
    ")\n",
    "\n",
    "from Quick.constants import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "download the dataset from this link --> https://www.unb.ca/cic/datasets/tor.html\n",
    "\n",
    "this is the paper --> https://www.scitepress.org/PublishedPapers/2017/61056/61056.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_a = '../data/Tor/CSV/Scenario-A/tor-nontor.csv' # labeled tor and non-tor \n",
    "scenario_b = '../data/Tor/CSV/Scenario-B/app_type.csv' # labeled (Browsing, Audio, CHAT, Mail, P2P, FT, VOIP, and Video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scenario a selected\n"
     ]
    }
   ],
   "source": [
    "scenario = input(\"a or b: \")\n",
    "\n",
    "if scenario == 'a':\n",
    "    dataset = pd.read_csv(scenario_a)\n",
    "    print('scenario a selected')\n",
    "elif scenario == 'b':\n",
    "    dataset = pd.read_csv(scenario_b)\n",
    "    print('scenario b selected')\n",
    "else:\n",
    "    print('scenario selection failed')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "preproccesing..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source IP</th>\n",
       "      <th>Source Port</th>\n",
       "      <th>Destination IP</th>\n",
       "      <th>Destination Port</th>\n",
       "      <th>Protocol</th>\n",
       "      <th>Flow Duration</th>\n",
       "      <th>Flow Bytes/s</th>\n",
       "      <th>Flow Packets/s</th>\n",
       "      <th>Flow IAT Mean</th>\n",
       "      <th>Flow IAT Std</th>\n",
       "      <th>...</th>\n",
       "      <th>Bwd IAT Min</th>\n",
       "      <th>Active Mean</th>\n",
       "      <th>Active Std</th>\n",
       "      <th>Active Max</th>\n",
       "      <th>Active Min</th>\n",
       "      <th>Idle Mean</th>\n",
       "      <th>Idle Std</th>\n",
       "      <th>Idle Max</th>\n",
       "      <th>Idle Min</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.0.2.15</td>\n",
       "      <td>53913</td>\n",
       "      <td>216.58.208.46</td>\n",
       "      <td>80</td>\n",
       "      <td>6</td>\n",
       "      <td>435</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4597.701149</td>\n",
       "      <td>435.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>nonTOR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.0.2.15</td>\n",
       "      <td>53913</td>\n",
       "      <td>216.58.208.46</td>\n",
       "      <td>80</td>\n",
       "      <td>6</td>\n",
       "      <td>259</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7722.007722</td>\n",
       "      <td>259.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>nonTOR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.0.2.15</td>\n",
       "      <td>53913</td>\n",
       "      <td>216.58.208.46</td>\n",
       "      <td>80</td>\n",
       "      <td>6</td>\n",
       "      <td>891</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2244.668911</td>\n",
       "      <td>891.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>nonTOR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.0.2.15</td>\n",
       "      <td>53913</td>\n",
       "      <td>216.58.208.46</td>\n",
       "      <td>80</td>\n",
       "      <td>6</td>\n",
       "      <td>1074</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1862.197393</td>\n",
       "      <td>1074.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>nonTOR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.0.2.15</td>\n",
       "      <td>53913</td>\n",
       "      <td>216.58.208.46</td>\n",
       "      <td>80</td>\n",
       "      <td>6</td>\n",
       "      <td>315</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6349.206349</td>\n",
       "      <td>315.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>nonTOR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67829</th>\n",
       "      <td>131.202.240.183</td>\n",
       "      <td>7116</td>\n",
       "      <td>239.255.255.250</td>\n",
       "      <td>1900</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>nonTOR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67830</th>\n",
       "      <td>131.202.240.183</td>\n",
       "      <td>7116</td>\n",
       "      <td>239.255.255.250</td>\n",
       "      <td>1900</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>nonTOR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67831</th>\n",
       "      <td>131.202.240.87</td>\n",
       "      <td>11365</td>\n",
       "      <td>31.13.73.1</td>\n",
       "      <td>443</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>nonTOR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67832</th>\n",
       "      <td>131.202.6.26</td>\n",
       "      <td>13000</td>\n",
       "      <td>131.202.240.87</td>\n",
       "      <td>64584</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>nonTOR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67833</th>\n",
       "      <td>38.124.168.119</td>\n",
       "      <td>80</td>\n",
       "      <td>131.202.240.87</td>\n",
       "      <td>65089</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>nonTOR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>67834 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Source IP   Source Port   Destination IP   Destination Port  \\\n",
       "0            10.0.2.15         53913    216.58.208.46                 80   \n",
       "1            10.0.2.15         53913    216.58.208.46                 80   \n",
       "2            10.0.2.15         53913    216.58.208.46                 80   \n",
       "3            10.0.2.15         53913    216.58.208.46                 80   \n",
       "4            10.0.2.15         53913    216.58.208.46                 80   \n",
       "...                ...           ...              ...                ...   \n",
       "67829  131.202.240.183          7116  239.255.255.250               1900   \n",
       "67830  131.202.240.183          7116  239.255.255.250               1900   \n",
       "67831   131.202.240.87         11365       31.13.73.1                443   \n",
       "67832     131.202.6.26         13000   131.202.240.87              64584   \n",
       "67833   38.124.168.119            80   131.202.240.87              65089   \n",
       "\n",
       "        Protocol   Flow Duration   Flow Bytes/s   Flow Packets/s  \\\n",
       "0              6             435            0.0      4597.701149   \n",
       "1              6             259            0.0      7722.007722   \n",
       "2              6             891            0.0      2244.668911   \n",
       "3              6            1074            0.0      1862.197393   \n",
       "4              6             315            0.0      6349.206349   \n",
       "...          ...             ...            ...              ...   \n",
       "67829         17               0            inf              inf   \n",
       "67830         17               0            inf              inf   \n",
       "67831          6               0            inf              inf   \n",
       "67832          6               0            NaN              inf   \n",
       "67833          6               0            NaN              inf   \n",
       "\n",
       "        Flow IAT Mean   Flow IAT Std  ...   Bwd IAT Min  Active Mean  \\\n",
       "0               435.0            0.0  ...             0            0   \n",
       "1               259.0            0.0  ...             0            0   \n",
       "2               891.0            0.0  ...             0            0   \n",
       "3              1074.0            0.0  ...             0            0   \n",
       "4               315.0            0.0  ...             0            0   \n",
       "...               ...            ...  ...           ...          ...   \n",
       "67829             0.0            0.0  ...             0            0   \n",
       "67830             0.0            0.0  ...             0            0   \n",
       "67831             0.0            0.0  ...             0            0   \n",
       "67832             0.0            0.0  ...             0            0   \n",
       "67833             0.0            0.0  ...             0            0   \n",
       "\n",
       "        Active Std   Active Max   Active Min  Idle Mean   Idle Std   Idle Max  \\\n",
       "0                0            0            0          0          0          0   \n",
       "1                0            0            0          0          0          0   \n",
       "2                0            0            0          0          0          0   \n",
       "3                0            0            0          0          0          0   \n",
       "4                0            0            0          0          0          0   \n",
       "...            ...          ...          ...        ...        ...        ...   \n",
       "67829            0            0            0          0          0          0   \n",
       "67830            0            0            0          0          0          0   \n",
       "67831            0            0            0          0          0          0   \n",
       "67832            0            0            0          0          0          0   \n",
       "67833            0            0            0          0          0          0   \n",
       "\n",
       "        Idle Min   label  \n",
       "0              0  nonTOR  \n",
       "1              0  nonTOR  \n",
       "2              0  nonTOR  \n",
       "3              0  nonTOR  \n",
       "4              0  nonTOR  \n",
       "...          ...     ...  \n",
       "67829          0  nonTOR  \n",
       "67830          0  nonTOR  \n",
       "67831          0  nonTOR  \n",
       "67832          0  nonTOR  \n",
       "67833          0  nonTOR  \n",
       "\n",
       "[67834 rows x 29 columns]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "nonTOR    59790\n",
       "TOR        8044\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no need for either of these\n",
    "\n",
    "# one hot encode\n",
    "# one_hot_encoded = pd.get_dummies(dataset['label'], prefix='label')\n",
    "# dataset = pd.concat([dataset, one_hot_encoded], axis=1)\n",
    "# dataset.drop('label', axis=1, inplace=True) # drop og\n",
    "# dataset\n",
    "\n",
    "# label encode \n",
    "# le = LabelEncoder()\n",
    "# dataset['label'] = le.fit_transform(dataset['label'])\n",
    "# dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop na's\n",
    "dataset.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Source_IP', '_Source_Port', '_Destination_IP', '_Destination_Port',\n",
       "       '_Protocol', '_Flow_Duration', '_Flow_Bytes/s', '_Flow_Packets/s',\n",
       "       '_Flow_IAT_Mean', '_Flow_IAT_Std', '_Flow_IAT_Max', '_Flow_IAT_Min',\n",
       "       'Fwd_IAT_Mean', '_Fwd_IAT_Std', '_Fwd_IAT_Max', '_Fwd_IAT_Min',\n",
       "       'Bwd_IAT_Mean', '_Bwd_IAT_Std', '_Bwd_IAT_Max', '_Bwd_IAT_Min',\n",
       "       'Active_Mean', '_Active_Std', '_Active_Max', '_Active_Min', 'Idle_Mean',\n",
       "       '_Idle_Std', '_Idle_Max', '_Idle_Min', 'label'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get rid of the spaces (dataset spacing is wack)\n",
    "dataset.rename(columns=lambda x: x.replace(' ', '_'), inplace=True)\n",
    "dataset.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scenario a\n",
    "\n",
    "Index(['Source_IP', '_Source_Port', '_Destination_IP', '_Destination_Port',\n",
    "       '_Protocol', '_Flow_Duration', '_Flow_Bytes/s', '_Flow_Packets/s',\n",
    "       '_Flow_IAT_Mean', '_Flow_IAT_Std', '_Flow_IAT_Max', '_Flow_IAT_Min',\n",
    "       'Fwd_IAT_Mean', '_Fwd_IAT_Std', '_Fwd_IAT_Max', '_Fwd_IAT_Min',\n",
    "       'Bwd_IAT_Mean', '_Bwd_IAT_Std', '_Bwd_IAT_Max', '_Bwd_IAT_Min',\n",
    "       'Active_Mean', '_Active_Std', '_Active_Max', '_Active_Min', 'Idle_Mean',\n",
    "       '_Idle_Std', '_Idle_Max', '_Idle_Min', 'label'],\n",
    "      dtype='object')\n",
    "\n",
    "scenario b\n",
    "\n",
    "Index(['Source_IP', '_Source_Port', '_Destination_IP', '_Destination_Port',\n",
    "       '_Protocol', '_Flow_Duration', '_Flow_Bytes/s', '_Flow_Packets/s',\n",
    "       '_Flow_IAT_Mean', '_Flow_IAT_Std', '_Flow_IAT_Max', '_Flow_IAT_Min',\n",
    "       'Fwd_IAT_Mean', '_Fwd_IAT_Std', '_Fwd_IAT_Max', '_Fwd_IAT_Min',\n",
    "       'Bwd_IAT_Mean', '_Bwd_IAT_Std', '_Bwd_IAT_Max', '_Bwd_IAT_Min',\n",
    "       'Active_Mean', '_Active_Std', '_Active_Max', '_Active_Min', 'Idle_Mean',\n",
    "       '_Idle_Std', '_Idle_Max', '_Idle_Min', 'label'],\n",
    "      dtype='object')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_columns = [\n",
    "    'Source_IP', '_Source_Port',\n",
    "]\n",
    "\n",
    "destination_columns = [\n",
    "    '_Destination_IP', '_Destination_Port',\n",
    "]\n",
    "\n",
    "flow_columns = [\n",
    "   '_Flow_Duration', '_Flow_Bytes/s', '_Flow_Packets/s',\n",
    "]\n",
    "\n",
    "flow_iat_columns = [\n",
    "    '_Flow_IAT_Mean', '_Flow_IAT_Std', '_Flow_IAT_Max', '_Flow_IAT_Min',\n",
    "]\n",
    "\n",
    "fwd_iat_columns = [\n",
    "    'Fwd_IAT_Mean', '_Fwd_IAT_Std', '_Fwd_IAT_Max', '_Fwd_IAT_Min',\n",
    "]\n",
    "\n",
    "bwd_iat_columns = [\n",
    "   'Bwd_IAT_Mean', '_Bwd_IAT_Std', '_Bwd_IAT_Max', '_Bwd_IAT_Min',\n",
    "]\n",
    "\n",
    "active_columns = [\n",
    "    'Active_Mean', '_Active_Std', '_Active_Max', '_Active_Min', \n",
    "]\n",
    "\n",
    "idle_columns = [\n",
    "    'Idle_Mean', '_Idle_Std', '_Idle_Max', '_Idle_Min',\n",
    "]\n",
    "\n",
    "label_columns = [\n",
    "    'label',\n",
    "]\n",
    "\n",
    "feature_groups = {\n",
    "    'flow_iat': flow_iat_columns,\n",
    "    'flow': flow_columns,\n",
    "    'bwd_iat': bwd_iat_columns,\n",
    "    'idle': idle_columns,\n",
    "}\n",
    "\n",
    "features = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for group in feature_groups.values():\n",
    "    features.extend(group)\n",
    "\n",
    "columns = features + label_columns\n",
    "\n",
    "# we reorder the columns\n",
    "df = dataset[columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiheadAttention(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        embedding_size     : int,\n",
    "        heads              : int,\n",
    "        device             : torch.device,\n",
    "    ) -> None:\n",
    "    \n",
    "        super(MultiheadAttention, self).__init__()\n",
    "\n",
    "        self.embedding_size      = embedding_size\n",
    "        self.heads               = heads\n",
    "\n",
    "        if embedding_size % heads != 0:\n",
    "            raise Exception(f'embedding_size must be divisible by heads. embedding_size: {embedding_size}, heads: {heads}')\n",
    "\n",
    "        self.query = nn.Linear(embedding_size, embedding_size, device = device)\n",
    "        self.key   = nn.Linear(embedding_size, embedding_size, device = device)\n",
    "        self.value = nn.Linear(embedding_size, embedding_size, device = device)\n",
    "\n",
    "        # The constant that is used to scale the dot product, we precompute it for efficiency\n",
    "        self.scaling_denominator = torch.tensor(\n",
    "            math.sqrt(embedding_size // heads), \n",
    "            dtype=torch.float32, \n",
    "            device=device\n",
    "        )\n",
    "\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(\n",
    "        self, \n",
    "        q: torch.Tensor, \n",
    "        v: torch.Tensor,\n",
    "        k: torch.Tensor\n",
    "    ):\n",
    "        '''\n",
    "            We perform multihead attention on the query embeddings using the encoder state as the key and value\n",
    "\n",
    "            shape:\n",
    "                x: (batch_size, total_num_queries, embedding_size)\n",
    "                encoder_state: (batch_size, lookback_size, embedding_size)\n",
    "                output: (batch_size, total_num_queries, embedding_size)\n",
    "        '''\n",
    "\n",
    "        # print(f\"q: {q.shape}\")\n",
    "\n",
    "        key  : torch.Tensor = self.key(k)\n",
    "        value: torch.Tensor = self.value(v)\n",
    "        query: torch.Tensor = self.query(q)\n",
    "\n",
    "        # we split the query, key, and value into heads\n",
    "        query = query.reshape(\n",
    "            query.shape[0],\n",
    "            query.shape[1],\n",
    "            self.heads,\n",
    "            self.embedding_size // self.heads\n",
    "        ).transpose(1, 2)\n",
    "\n",
    "        key = key.reshape(\n",
    "            key.shape[0],\n",
    "            key.shape[1],\n",
    "            self.heads,\n",
    "            self.embedding_size // self.heads\n",
    "        ).transpose(1, 2)\n",
    "\n",
    "        value = value.reshape(\n",
    "            value.shape[0],\n",
    "            value.shape[1],\n",
    "            self.heads,\n",
    "            self.embedding_size // self.heads\n",
    "        ).transpose(1, 2)\n",
    "\n",
    "        # we perform the attention\n",
    "        pre_attention = torch.matmul(query, key.transpose(-2, -1))/self.scaling_denominator\n",
    "\n",
    "        # print(f\"pre_attention: {pre_attention.shape}\")\n",
    "\n",
    "        # we apply the softmax to the pre_attention\n",
    "        distribution = self.softmax(pre_attention)\n",
    "\n",
    "\n",
    "        # print(f\"distribution: {distribution.shape}\")\n",
    "        # print(f\"value: {value.shape}\")\n",
    "\n",
    "        # we multiply the distribution by the value to give the attention output\n",
    "        attention = torch.einsum('bhqk,bhkd->bhqd', distribution, value)\n",
    "\n",
    "        # print(f\"attention: {attention.shape}\")\n",
    "\n",
    "\n",
    "        # Finally, we reshape the attention, transitioning between the following shapes:\n",
    "        #       attention shape: batch_size, heads, total_num_queries, embedding_size // heads\n",
    "        #       final shape: batch_size, total_num_queries, embedding_size\n",
    "        full_attention = attention.transpose(1, 2).reshape(\n",
    "            attention.shape[0],\n",
    "            attention.shape[-2],\n",
    "            self.embedding_size\n",
    "        )\n",
    "\n",
    "        # print(f\"full_attention: {full_attention.shape}\")\n",
    "\n",
    "        return full_attention\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        embedding_size     : int,\n",
    "        heads              : int,\n",
    "        device             : torch.device,\n",
    "        forward_expansion  : int      = 4,\n",
    "        dropout            : float    = 0.0,\n",
    "        pre_norm           : bool     = False,\n",
    "        activation = nn.ReLU(),\n",
    "    ) -> None:\n",
    "    \n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.embedding_size     = embedding_size\n",
    "        self.heads              = heads\n",
    "        self.forward_expansion  = forward_expansion\n",
    "        self.dropout            = dropout\n",
    "        self.activation         = activation\n",
    "        self.pre_norm           = pre_norm\n",
    "\n",
    "        self.attention = MultiheadAttention(embedding_size, heads, device)\n",
    "\n",
    "        self.norm_1 = nn.LayerNorm(embedding_size)\n",
    "        self.norm_2 = nn.LayerNorm(embedding_size)\n",
    "\n",
    "        self.hidden_size = int(embedding_size * forward_expansion)\n",
    "\n",
    "        self.feed_forward = nn.Sequential(\n",
    "            nn.Linear(embedding_size, self.hidden_size),\n",
    "            self.activation,\n",
    "            nn.Linear(self.hidden_size, embedding_size),\n",
    "        )\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        x: torch.Tensor,\n",
    "    ) -> torch.Tensor:\n",
    "        '''\n",
    "            We perform multihead attention. \n",
    "            \n",
    "            If we prenorm, we apply layer norm before the attention and feed forward layers,\n",
    "                otherwise we apply it after \n",
    "        '''\n",
    "\n",
    "        # print(f\"x: {x.shape}\")\n",
    "\n",
    "        if self.pre_norm:\n",
    "            x_hat = self.norm_1(x)\n",
    "            attention = self.attention(x_hat, x_hat, x_hat)\n",
    "            x_hat = x + self.dropout(attention)\n",
    "        else: \n",
    "            attention = self.attention(x, x, x)\n",
    "            x_hat = self.norm_1(x + self.dropout(attention))\n",
    "\n",
    "\n",
    "        if self.pre_norm:\n",
    "            x_hat = self.norm_2(x_hat)\n",
    "            feed_forward = self.feed_forward(x_hat)\n",
    "            x_hat = x_hat + self.dropout(feed_forward)\n",
    "        else:\n",
    "            feed_forward = self.feed_forward(x_hat)\n",
    "            x_hat = self.norm_2(x_hat + self.dropout(feed_forward))\n",
    "\n",
    "        return x_hat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GroupEmbedding(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        embedding_size: int,\n",
    "        input_size: int,\n",
    "        use_rff: bool,\n",
    "        device: torch.device,\n",
    "        rff_dim: int = 64,\n",
    "        rff_std: float = 2.5,\n",
    "        learnable_rff_std: bool = False,\n",
    "        activation: nn.Module = nn.ReLU(),\n",
    "    ) -> None:\n",
    "        super(GroupEmbedding, self).__init__()\n",
    "\n",
    "        self.embedding_size = embedding_size\n",
    "        self.device = device\n",
    "        self.use_rff = use_rff\n",
    "        self.rff_dim = rff_dim\n",
    "        self.rff_std = rff_std\n",
    "        self.learnable_rff_std = learnable_rff_std\n",
    "\n",
    "\n",
    "        if use_rff:\n",
    "            self.rff = GaussianEncoding(\n",
    "                rff_std,\n",
    "                input_size,\n",
    "                rff_dim\n",
    "            ).to(device)\n",
    "\n",
    "        if learnable_rff_std:\n",
    "            self.std_vec = nn.Parameter(torch.ones(input_size, device=device))\n",
    "            \n",
    "        \n",
    "        self.linear_size = input_size + 2*self.rff_dim if use_rff else input_size\n",
    "\n",
    "        self.linear = nn.Linear(\n",
    "            self.linear_size,\n",
    "            embedding_size, \n",
    "            device=device\n",
    "        )\n",
    "\n",
    "        self.activation = activation\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        '''\n",
    "            We embed the input using the strategy found suggested in the following papers: \n",
    "                Time2Vec: Learning a Vector Representation of Time: \n",
    "                    https://arxiv.org/abs/1907.05321\n",
    "\n",
    "                On Embeddings for Numerical Features in Tabular Deep Learning: \n",
    "                    https://arxiv.org/abs/2203.05556\n",
    "                    \n",
    "                Fourier Features Let Networks Learn High Frequency Functions in Low Dimensional Domains: \n",
    "                    https://arxiv.org/abs/2006.10739\n",
    "        \n",
    "            We first pass the the input through an encoding layer, which is either an RFF layer or nothing.\n",
    "            If there is an encoding layer, we concatenate the encoding with the input.\n",
    "            Then, we pass the output of the encoding layer through a linear layer and an activation function.\n",
    "        '''\n",
    "\n",
    "        if self.use_rff:\n",
    "            if self.learnable_rff_std:\n",
    "                x = x * self.std_vec\n",
    "\n",
    "            rff = self.rff(x)\n",
    "            # print(f\"rff: {rff.shape}\")\n",
    "            # print(f\"x: {x.shape}\")\n",
    "            x = torch.cat((x, rff), dim=-1)\n",
    "\n",
    "        # print(f'post rff x shape: {x.shape}')\n",
    "        # print(f\"self.linear_size: {self.linear_size}\")\n",
    "\n",
    "        x = self.linear(x)\n",
    "        x = self.activation(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DebugLayer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        verbose: bool = False,\n",
    "        message: str = '',\n",
    "    ) -> None:\n",
    "        super(DebugLayer, self).__init__()\n",
    "        self.verbose = verbose\n",
    "        self.message = message\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        if self.verbose:\n",
    "            print(f\"{self.message}: {x.shape}\")\n",
    "            self.verbose = False\n",
    "            \n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlowTransformer(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        input_features = 62, \n",
    "        output_features = 8, \n",
    "        device = torch.device('cpu'), \n",
    "        config: dict = {\n",
    "            'feature_groups': feature_groups,\n",
    "            'activation': nn.ReLU(),\n",
    "            'verbose': True,\n",
    "            'embeddings': {\n",
    "                'embedding_size': 64,\n",
    "                'use_rff': True,\n",
    "                'rff_dim': 64,\n",
    "                'rff_std': 2.5,\n",
    "                'learnable_rff_std': False,\n",
    "            },\n",
    "            'encoder':{\n",
    "                'layers': 2,\n",
    "                'heads': 4,\n",
    "                'forward_expansion': 2,\n",
    "                'pre_norm': False,\n",
    "                'dropout': 0.0,\n",
    "            },\n",
    "            'aggregation': {\n",
    "                'type': 'LSTM',\n",
    "                'layers': 1,\n",
    "            },\n",
    "            'classification_head': {\n",
    "                'layers': 2,\n",
    "                'hidden_size': 64,\n",
    "                'batch_norm': False,\n",
    "                'activation': nn.ReLU(),\n",
    "            }\n",
    "        }\n",
    "    ):\n",
    "        '''\n",
    "            This will be a transformer that takes feature groups and transforms them into\n",
    "                embedding vectors. The embedding vectors will pass through a series of\n",
    "                encoder layers and then will be aggregated into a single vector. This vector\n",
    "                will then be passed into a classification head.\n",
    "\n",
    "            We will be using this in conjunction with a test harness in the quick library.\n",
    "                Every model that is used in this manner will need to have the 4 init parameters:\n",
    "                    # of input features\n",
    "                    # of output features\n",
    "                    device\n",
    "                    a config dictionary\n",
    "\n",
    "            The config dictionary will be used to specify the architecture of the model, and \n",
    "                even when not using a config, one must be passed through the test harness in order\n",
    "                to work correctly.\n",
    "            \n",
    "        '''\n",
    "\n",
    "        super(FlowTransformer, self).__init__()\n",
    "\n",
    "        self.input_features = input_features\n",
    "        self.output_features = output_features\n",
    "        self.device = device\n",
    "        self.config = config\n",
    "        self.verbose = config['verbose']\n",
    "\n",
    "        print(f'input features: {self.input_features}')\n",
    "        print(f'output features: {self.output_features}')\n",
    "\n",
    "        # First, we create our embeddings for each feature group\n",
    "\n",
    "        self.feature_groups = config['feature_groups']\n",
    "        self.embedding_size = config['embeddings']['embedding_size']\n",
    "\n",
    "        self.use_rff = config['embeddings']['use_rff']\n",
    "        self.rff_dim = config['embeddings']['rff_dim']\n",
    "        self.rff_std = config['embeddings']['rff_std']\n",
    "        self.learnable_rff_std = config['embeddings']['learnable_rff_std']\n",
    "\n",
    "        self.activation = config['activation']\n",
    "\n",
    "\n",
    "\n",
    "        self.embeddings = nn.ModuleDict()\n",
    "\n",
    "        for group, columns in self.feature_groups.items():\n",
    "            self.embeddings[group] = GroupEmbedding(\n",
    "                config['embeddings']['embedding_size'],\n",
    "                len(columns),\n",
    "                self.use_rff,\n",
    "                device,\n",
    "                self.rff_dim,\n",
    "                self.rff_std,\n",
    "                self.learnable_rff_std,\n",
    "                self.activation\n",
    "            )\n",
    "\n",
    "        # Next, we create our encoder layers\n",
    "\n",
    "        self.encoder_layers = config['encoder']['layers']\n",
    "        self.encoder_heads = config['encoder']['heads']\n",
    "        self.encoder_forward_expansion = config['encoder']['forward_expansion']\n",
    "        self.encoder_pre_norm = config['encoder']['pre_norm']\n",
    "        self.encoder_dropout = config['encoder']['dropout']\n",
    "\n",
    "        encoder_layers = [\n",
    "            Encoder(\n",
    "                self.embedding_size,\n",
    "                self.encoder_heads,\n",
    "                self.device,\n",
    "                self.encoder_forward_expansion,\n",
    "                self.encoder_dropout,\n",
    "                self.encoder_pre_norm,\n",
    "                self.activation\n",
    "            ) for _ in range(self.encoder_layers)\n",
    "        ]\n",
    "        \n",
    "        self.encoder = nn.Sequential(*encoder_layers)\n",
    "        \n",
    "        # Now, we create our aggregation layer\n",
    "        \n",
    "        self.aggregation_type = config['aggregation']['type']\n",
    "        \n",
    "\n",
    "        # Add your own aggregation layers here\n",
    "        if self.aggregation_type == 'LSTM':\n",
    "            self.aggregation = nn.LSTM(\n",
    "                input_size = self.embedding_size,\n",
    "                hidden_size = self.embedding_size,\n",
    "                num_layers = config['aggregation']['layers'],\n",
    "                batch_first = True,\n",
    "            ).to(device)\n",
    "        else:\n",
    "            raise Exception(f'aggregation type {self.aggregation_type} not supported')\n",
    "\n",
    "    \n",
    "        # Finally, we create our classification head\n",
    "        self.classification_head_layers = config['classification_head']['layers']\n",
    "        self.classification_head_hidden_size = config['classification_head']['hidden_size']\n",
    "        self.classification_head_batch_norm = config['classification_head']['batch_norm']\n",
    "        self.classification_head_activation = config['classification_head']['activation']\n",
    "\n",
    "        self.classification_head = []\n",
    "        \n",
    "        for i in range(self.classification_head_layers):\n",
    "                \n",
    "            input_size = self.embedding_size if i == 0 else self.classification_head_hidden_size\n",
    "\n",
    "            self.classification_head.append(\n",
    "                nn.Linear(\n",
    "                    input_size,\n",
    "                    self.classification_head_hidden_size,\n",
    "                    device = self.device\n",
    "                )\n",
    "            )\n",
    "\n",
    "               \n",
    "            if self.classification_head_batch_norm:\n",
    "                self.classification_head.append(\n",
    "                    nn.BatchNorm1d(\n",
    "                        self.classification_head_hidden_size,\n",
    "                        device = self.device\n",
    "                    )\n",
    "                )\n",
    "\n",
    "            self.classification_head.append(\n",
    "                self.classification_head_activation\n",
    "            )\n",
    "\n",
    "            if self.verbose:\n",
    "                self.classification_head.append(\n",
    "                    DebugLayer(\n",
    "                        verbose = self.verbose, \n",
    "                        message = f\"Classification Head Layer {i}\"\n",
    "                    )\n",
    "                )\n",
    "\n",
    "        self.classification_head.append(\n",
    "            nn.Linear(\n",
    "                self.classification_head_hidden_size,\n",
    "                self.output_features,\n",
    "                device = self.device\n",
    "            )\n",
    "        )\n",
    "\n",
    "        self.classification_head = nn.Sequential(*self.classification_head)\n",
    "\n",
    "\n",
    "        self.flag = config['verbose']\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # First, we embed the input\n",
    "        embeddings = []\n",
    "        current_idx = 0\n",
    "\n",
    "        batch_size = x.shape[0]\n",
    "\n",
    "        for group, columns in self.feature_groups.items():\n",
    "            group_embedding = self.embeddings[group](x[:, current_idx:current_idx + len(columns)])\n",
    "            group_embedding = group_embedding.reshape(batch_size, 1, self.embedding_size)\n",
    "            embeddings.append(group_embedding)\n",
    "            current_idx += len(columns)\n",
    "\n",
    "        # Next, we concatenate the embeddings\n",
    "        embedding_tensor = torch.cat(embeddings, dim=1)\n",
    "\n",
    "        # print(f'embedding tensor shape: {embedding_tensor.shape}')\n",
    "\n",
    "        # Then, we pass the embeddings through the encoder layers\n",
    "        embeddings = self.encoder(embedding_tensor)\n",
    "\n",
    "        # Next, we aggregate the embeddings\n",
    "        if self.aggregation_type == 'LSTM':\n",
    "            embeddings, _ = self.aggregation(embeddings)\n",
    "            # print(f\"Raw aggregation shape: {embeddings.shape}\")\n",
    "            embeddings = embeddings[:, -1, :].reshape(batch_size, self.embedding_size)\n",
    "            # print(f\"Post aggregation shape: {embeddings.shape}\")\n",
    "\n",
    "        # Finally, we pass the embeddings through the classification head\n",
    "        output = self.classification_head(embeddings)\n",
    "\n",
    "\n",
    "        if self.flag:\n",
    "            print(f\"embeddings shape: {embeddings.shape}\")\n",
    "            print(f\"aggregated embeddings shape: {embeddings.shape}\")\n",
    "            print(f\"output shape: {output.shape}\")\n",
    "\n",
    "            self.flag = False\n",
    "\n",
    "        # raise Exception('stop')\n",
    "        return output\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Input Data: (67832, 16)\n",
      "input features: 15\n",
      "output features: 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Head Layer 0: torch.Size([64, 64])\n",
      "Classification Head Layer 1: torch.Size([64, 64])\n",
      "embeddings shape: torch.Size([64, 64])\n",
      "aggregated embeddings shape: torch.Size([64, 64])\n",
      "output shape: torch.Size([64, 2])\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for dimension 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[149], line 11\u001b[0m\n\u001b[0;32m      1\u001b[0m METRICS: \u001b[39mlist\u001b[39m \u001b[39m=\u001b[39m [\n\u001b[0;32m      2\u001b[0m     accuracy,\n\u001b[0;32m      3\u001b[0m     BalancedAccuracy(),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      8\u001b[0m     Recall(average\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmacro\u001b[39m\u001b[39m'\u001b[39m),\n\u001b[0;32m      9\u001b[0m ]\n\u001b[1;32m---> 11\u001b[0m results_flow_transformer_1 \u001b[39m=\u001b[39m run_torch_nn_experiment(\n\u001b[0;32m     12\u001b[0m     df, \n\u001b[0;32m     13\u001b[0m     scenario, \n\u001b[0;32m     14\u001b[0m     \u001b[39m'\u001b[39;49m\u001b[39mlabel\u001b[39;49m\u001b[39m'\u001b[39;49m, \n\u001b[0;32m     15\u001b[0m     FlowTransformer,\n\u001b[0;32m     16\u001b[0m     metrics\u001b[39m=\u001b[39;49mMETRICS,\n\u001b[0;32m     17\u001b[0m     config \u001b[39m=\u001b[39;49m {\n\u001b[0;32m     18\u001b[0m         \u001b[39m'\u001b[39;49m\u001b[39mfeature_groups\u001b[39;49m\u001b[39m'\u001b[39;49m: feature_groups,\n\u001b[0;32m     19\u001b[0m         \u001b[39m'\u001b[39;49m\u001b[39mactivation\u001b[39;49m\u001b[39m'\u001b[39;49m: nn\u001b[39m.\u001b[39;49mReLU(),\n\u001b[0;32m     20\u001b[0m         \u001b[39m'\u001b[39;49m\u001b[39mverbose\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m     21\u001b[0m         \u001b[39m'\u001b[39;49m\u001b[39membeddings\u001b[39;49m\u001b[39m'\u001b[39;49m: {\n\u001b[0;32m     22\u001b[0m             \u001b[39m'\u001b[39;49m\u001b[39membedding_size\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39m64\u001b[39;49m,\n\u001b[0;32m     23\u001b[0m             \u001b[39m'\u001b[39;49m\u001b[39muse_rff\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m     24\u001b[0m             \u001b[39m'\u001b[39;49m\u001b[39mrff_dim\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39m64\u001b[39;49m,\n\u001b[0;32m     25\u001b[0m             \u001b[39m'\u001b[39;49m\u001b[39mrff_std\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39m2.5\u001b[39;49m,\n\u001b[0;32m     26\u001b[0m             \u001b[39m'\u001b[39;49m\u001b[39mlearnable_rff_std\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m     27\u001b[0m         },\n\u001b[0;32m     28\u001b[0m         \u001b[39m'\u001b[39;49m\u001b[39mencoder\u001b[39;49m\u001b[39m'\u001b[39;49m:{\n\u001b[0;32m     29\u001b[0m             \u001b[39m'\u001b[39;49m\u001b[39mlayers\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39m2\u001b[39;49m,\n\u001b[0;32m     30\u001b[0m             \u001b[39m'\u001b[39;49m\u001b[39mheads\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39m4\u001b[39;49m,\n\u001b[0;32m     31\u001b[0m             \u001b[39m'\u001b[39;49m\u001b[39mforward_expansion\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39m2\u001b[39;49m,\n\u001b[0;32m     32\u001b[0m             \u001b[39m'\u001b[39;49m\u001b[39mpre_norm\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m     33\u001b[0m             \u001b[39m'\u001b[39;49m\u001b[39mdropout\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39m0.0\u001b[39;49m,\n\u001b[0;32m     34\u001b[0m         },\n\u001b[0;32m     35\u001b[0m         \u001b[39m'\u001b[39;49m\u001b[39maggregation\u001b[39;49m\u001b[39m'\u001b[39;49m: {\n\u001b[0;32m     36\u001b[0m             \u001b[39m'\u001b[39;49m\u001b[39mtype\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39m'\u001b[39;49m\u001b[39mLSTM\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[0;32m     37\u001b[0m             \u001b[39m'\u001b[39;49m\u001b[39mlayers\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39m1\u001b[39;49m,\n\u001b[0;32m     38\u001b[0m         },\n\u001b[0;32m     39\u001b[0m         \u001b[39m'\u001b[39;49m\u001b[39mclassification_head\u001b[39;49m\u001b[39m'\u001b[39;49m: {\n\u001b[0;32m     40\u001b[0m             \u001b[39m'\u001b[39;49m\u001b[39mlayers\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39m2\u001b[39;49m,\n\u001b[0;32m     41\u001b[0m             \u001b[39m'\u001b[39;49m\u001b[39mhidden_size\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39m64\u001b[39;49m,\n\u001b[0;32m     42\u001b[0m             \u001b[39m'\u001b[39;49m\u001b[39mbatch_norm\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m     43\u001b[0m             \u001b[39m'\u001b[39;49m\u001b[39mactivation\u001b[39;49m\u001b[39m'\u001b[39;49m: nn\u001b[39m.\u001b[39;49mReLU(),\n\u001b[0;32m     44\u001b[0m         }\n\u001b[0;32m     45\u001b[0m     }\n\u001b[0;32m     46\u001b[0m )\n\u001b[0;32m     49\u001b[0m model \u001b[39m=\u001b[39m results_flow_transformer_1\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mmodel\n\u001b[0;32m     51\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mLearnable Parameters: \u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m{\u001b[39;00m\u001b[39msum\u001b[39m(p\u001b[39m.\u001b[39mnumel()\u001b[39m \u001b[39m\u001b[39mfor\u001b[39;00m\u001b[39m \u001b[39mp\u001b[39m \u001b[39m\u001b[39min\u001b[39;00m\u001b[39m \u001b[39mmodel\u001b[39m.\u001b[39mparameters()\u001b[39m \u001b[39m\u001b[39mif\u001b[39;00m\u001b[39m \u001b[39mp\u001b[39m.\u001b[39mrequires_grad)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\prime\\OneDrive\\Documents\\CMU\\research\\TrafficFlowForecasting\\prototype\\Quick\\runners\\torch.py:134\u001b[0m, in \u001b[0;36mrun_torch_nn_experiment\u001b[1;34m(df, file_name, target_label, model, split, categorical, procs, leave_out, epochs, batch_size, metrics, callbacks, lr_choice, name, fit_choice, no_bar, config)\u001b[0m\n\u001b[0;32m    131\u001b[0m p \u001b[39m=\u001b[39m pathlib\u001b[39m.\u001b[39mPath(file_name)\n\u001b[0;32m    132\u001b[0m file_name: \u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(p\u001b[39m.\u001b[39mparts[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m])\n\u001b[1;32m--> 134\u001b[0m learner, results \u001b[39m=\u001b[39m run_model(\n\u001b[0;32m    135\u001b[0m     name,\n\u001b[0;32m    136\u001b[0m     learner,\n\u001b[0;32m    137\u001b[0m     epochs,\n\u001b[0;32m    138\u001b[0m     no_bar,\n\u001b[0;32m    139\u001b[0m     lr_choice,\n\u001b[0;32m    140\u001b[0m     fit_choice\n\u001b[0;32m    141\u001b[0m )\n\u001b[0;32m    143\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mloss: \u001b[39m\u001b[39m{\u001b[39;00mresults[\u001b[39m0\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m, accuracy: \u001b[39m\u001b[39m{\u001b[39;00mresults[\u001b[39m1\u001b[39m]\u001b[39m*\u001b[39m\u001b[39m100\u001b[39m\u001b[39m:\u001b[39;00m\u001b[39m .2f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m%\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    145\u001b[0m \u001b[39m# we add a target_type_ attribute to our model so yellowbrick knows how to make the visualizations\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\prime\\OneDrive\\Documents\\CMU\\research\\TrafficFlowForecasting\\prototype\\Quick\\runners\\utils.py:193\u001b[0m, in \u001b[0;36mrun_model\u001b[1;34m(name, learner, epochs, no_bar, lr_choice, fit_choice, lr_funcs)\u001b[0m\n\u001b[0;32m    188\u001b[0m lr_choice: \u001b[39mint\u001b[39m \u001b[39m=\u001b[39m LEARNING_RATE_OPTIONS[lr_choice]\n\u001b[0;32m    191\u001b[0m \u001b[39mwith\u001b[39;00m learner\u001b[39m.\u001b[39mno_bar() \u001b[39mif\u001b[39;00m no_bar \u001b[39melse\u001b[39;00m contextlib\u001b[39m.\u001b[39mExitStack() \u001b[39mas\u001b[39;00m gs:\n\u001b[1;32m--> 193\u001b[0m     lr \u001b[39m=\u001b[39m learner\u001b[39m.\u001b[39;49mlr_find(suggest_funcs\u001b[39m=\u001b[39;49mlr_funcs)\n\u001b[0;32m    195\u001b[0m         \u001b[39m# fitting functions, they give different results, some networks perform better with different learning schedule during fitting\u001b[39;00m\n\u001b[0;32m    196\u001b[0m     \u001b[39mif\u001b[39;00m(fit_choice \u001b[39m==\u001b[39m FIT):\n",
      "File \u001b[1;32mc:\\Users\\prime\\anaconda3\\envs\\DL\\lib\\site-packages\\fastai\\callback\\schedule.py:304\u001b[0m, in \u001b[0;36mlr_find\u001b[1;34m(self, start_lr, end_lr, num_it, stop_div, show_plot, suggest_funcs)\u001b[0m\n\u001b[0;32m    302\u001b[0m \u001b[39mfor\u001b[39;00m func \u001b[39min\u001b[39;00m tuplify(suggest_funcs):\n\u001b[0;32m    303\u001b[0m     nms\u001b[39m.\u001b[39mappend(func\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(func, partial) \u001b[39melse\u001b[39;00m func\u001b[39m.\u001b[39mfunc\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m) \u001b[39m# deal with partials\u001b[39;00m\n\u001b[1;32m--> 304\u001b[0m     _suggestions\u001b[39m.\u001b[39mappend(func(lrs, losses, num_it))\n\u001b[0;32m    306\u001b[0m SuggestedLRs \u001b[39m=\u001b[39m collections\u001b[39m.\u001b[39mnamedtuple(\u001b[39m'\u001b[39m\u001b[39mSuggestedLRs\u001b[39m\u001b[39m'\u001b[39m, nms)\n\u001b[0;32m    307\u001b[0m lrs, pnts \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\prime\\anaconda3\\envs\\DL\\lib\\site-packages\\fastai\\callback\\schedule.py:231\u001b[0m, in \u001b[0;36mvalley\u001b[1;34m(lrs, losses, num_it)\u001b[0m\n\u001b[0;32m    228\u001b[0m sections \u001b[39m=\u001b[39m (max_end \u001b[39m-\u001b[39m max_start) \u001b[39m/\u001b[39m \u001b[39m3\u001b[39m\n\u001b[0;32m    229\u001b[0m idx \u001b[39m=\u001b[39m max_start \u001b[39m+\u001b[39m \u001b[39mint\u001b[39m(sections) \u001b[39m+\u001b[39m \u001b[39mint\u001b[39m(sections\u001b[39m/\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[1;32m--> 231\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mfloat\u001b[39m(lrs[idx]), (\u001b[39mfloat\u001b[39m(lrs[idx]), losses[idx])\n",
      "\u001b[1;31mIndexError\u001b[0m: index 0 is out of bounds for dimension 0 with size 0"
     ]
    }
   ],
   "source": [
    "METRICS: list = [\n",
    "    accuracy,\n",
    "    BalancedAccuracy(),\n",
    "    # RocAuc(),\n",
    "    MatthewsCorrCoef(),\n",
    "    F1Score(average='macro'),\n",
    "    Precision(average='macro'),\n",
    "    Recall(average='macro'),\n",
    "]\n",
    "\n",
    "results_flow_transformer_1 = run_torch_nn_experiment(\n",
    "    df, \n",
    "    scenario, \n",
    "    'label', \n",
    "    FlowTransformer,\n",
    "    metrics=METRICS,\n",
    "    config = {\n",
    "        'feature_groups': feature_groups,\n",
    "        'activation': nn.ReLU(),\n",
    "        'verbose': True,\n",
    "        'embeddings': {\n",
    "            'embedding_size': 64,\n",
    "            'use_rff': True,\n",
    "            'rff_dim': 64,\n",
    "            'rff_std': 2.5,\n",
    "            'learnable_rff_std': False,\n",
    "        },\n",
    "        'encoder':{\n",
    "            'layers': 2,\n",
    "            'heads': 4,\n",
    "            'forward_expansion': 2,\n",
    "            'pre_norm': False,\n",
    "            'dropout': 0.0,\n",
    "        },\n",
    "        'aggregation': {\n",
    "            'type': 'LSTM',\n",
    "            'layers': 1,\n",
    "        },\n",
    "        'classification_head': {\n",
    "            'layers': 2,\n",
    "            'hidden_size': 64,\n",
    "            'batch_norm': False,\n",
    "            'activation': nn.ReLU(),\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "model = results_flow_transformer_1.model.model.model\n",
    "\n",
    "print(f\"Learnable Parameters: \\t\\t\\t{sum(p.numel() for p in model.parameters() if p.requires_grad)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Input Data: (67832, 16)\n",
      "input features: 15\n",
      "output features: 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Head Layer 0: torch.Size([64, 64])\n",
      "Classification Head Layer 1: torch.Size([64, 64])\n",
      "embeddings shape: torch.Size([64, 128])\n",
      "aggregated embeddings shape: torch.Size([64, 128])\n",
      "output shape: torch.Size([64, 2])\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for dimension 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[121], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m results_flow_transformer_1 \u001b[39m=\u001b[39m run_torch_nn_experiment(\n\u001b[0;32m      2\u001b[0m     df, \n\u001b[0;32m      3\u001b[0m     scenario, \n\u001b[0;32m      4\u001b[0m     \u001b[39m'\u001b[39;49m\u001b[39mlabel\u001b[39;49m\u001b[39m'\u001b[39;49m, \n\u001b[0;32m      5\u001b[0m     FlowTransformer, \n\u001b[0;32m      6\u001b[0m     config \u001b[39m=\u001b[39;49m {\n\u001b[0;32m      7\u001b[0m         \u001b[39m'\u001b[39;49m\u001b[39mfeature_groups\u001b[39;49m\u001b[39m'\u001b[39;49m: feature_groups,\n\u001b[0;32m      8\u001b[0m         \u001b[39m'\u001b[39;49m\u001b[39mactivation\u001b[39;49m\u001b[39m'\u001b[39;49m: nn\u001b[39m.\u001b[39;49mReLU(),\n\u001b[0;32m      9\u001b[0m         \u001b[39m'\u001b[39;49m\u001b[39mverbose\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m     10\u001b[0m         \u001b[39m'\u001b[39;49m\u001b[39membeddings\u001b[39;49m\u001b[39m'\u001b[39;49m: {\n\u001b[0;32m     11\u001b[0m             \u001b[39m'\u001b[39;49m\u001b[39membedding_size\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39m128\u001b[39;49m,\n\u001b[0;32m     12\u001b[0m             \u001b[39m'\u001b[39;49m\u001b[39muse_rff\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m     13\u001b[0m             \u001b[39m'\u001b[39;49m\u001b[39mrff_dim\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39m128\u001b[39;49m,\n\u001b[0;32m     14\u001b[0m             \u001b[39m'\u001b[39;49m\u001b[39mrff_std\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39m.5\u001b[39;49m,\n\u001b[0;32m     15\u001b[0m             \u001b[39m'\u001b[39;49m\u001b[39mlearnable_rff_std\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m     16\u001b[0m         },\n\u001b[0;32m     17\u001b[0m         \u001b[39m'\u001b[39;49m\u001b[39mencoder\u001b[39;49m\u001b[39m'\u001b[39;49m:{\n\u001b[0;32m     18\u001b[0m             \u001b[39m'\u001b[39;49m\u001b[39mlayers\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39m2\u001b[39;49m,\n\u001b[0;32m     19\u001b[0m             \u001b[39m'\u001b[39;49m\u001b[39mheads\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39m4\u001b[39;49m,\n\u001b[0;32m     20\u001b[0m             \u001b[39m'\u001b[39;49m\u001b[39mforward_expansion\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39m2\u001b[39;49m,\n\u001b[0;32m     21\u001b[0m             \u001b[39m'\u001b[39;49m\u001b[39mpre_norm\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m     22\u001b[0m             \u001b[39m'\u001b[39;49m\u001b[39mdropout\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39m0.0\u001b[39;49m,\n\u001b[0;32m     23\u001b[0m         },\n\u001b[0;32m     24\u001b[0m         \u001b[39m'\u001b[39;49m\u001b[39maggregation\u001b[39;49m\u001b[39m'\u001b[39;49m: {\n\u001b[0;32m     25\u001b[0m             \u001b[39m'\u001b[39;49m\u001b[39mtype\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39m'\u001b[39;49m\u001b[39mLSTM\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[0;32m     26\u001b[0m             \u001b[39m'\u001b[39;49m\u001b[39mlayers\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39m1\u001b[39;49m,\n\u001b[0;32m     27\u001b[0m         },\n\u001b[0;32m     28\u001b[0m         \u001b[39m'\u001b[39;49m\u001b[39mclassification_head\u001b[39;49m\u001b[39m'\u001b[39;49m: {\n\u001b[0;32m     29\u001b[0m             \u001b[39m'\u001b[39;49m\u001b[39mlayers\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39m2\u001b[39;49m,\n\u001b[0;32m     30\u001b[0m             \u001b[39m'\u001b[39;49m\u001b[39mhidden_size\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39m64\u001b[39;49m,\n\u001b[0;32m     31\u001b[0m             \u001b[39m'\u001b[39;49m\u001b[39mbatch_norm\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m     32\u001b[0m             \u001b[39m'\u001b[39;49m\u001b[39mactivation\u001b[39;49m\u001b[39m'\u001b[39;49m: nn\u001b[39m.\u001b[39;49mReLU(),\n\u001b[0;32m     33\u001b[0m         }\n\u001b[0;32m     34\u001b[0m     }\n\u001b[0;32m     35\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\prime\\OneDrive\\Documents\\CMU\\research\\TrafficFlowForecasting\\prototype\\Quick\\runners\\torch.py:134\u001b[0m, in \u001b[0;36mrun_torch_nn_experiment\u001b[1;34m(df, file_name, target_label, model, split, categorical, procs, leave_out, epochs, batch_size, metrics, callbacks, lr_choice, name, fit_choice, no_bar, config)\u001b[0m\n\u001b[0;32m    131\u001b[0m p \u001b[39m=\u001b[39m pathlib\u001b[39m.\u001b[39mPath(file_name)\n\u001b[0;32m    132\u001b[0m file_name: \u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(p\u001b[39m.\u001b[39mparts[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m])\n\u001b[1;32m--> 134\u001b[0m learner, results \u001b[39m=\u001b[39m run_model(\n\u001b[0;32m    135\u001b[0m     name,\n\u001b[0;32m    136\u001b[0m     learner,\n\u001b[0;32m    137\u001b[0m     epochs,\n\u001b[0;32m    138\u001b[0m     no_bar,\n\u001b[0;32m    139\u001b[0m     lr_choice,\n\u001b[0;32m    140\u001b[0m     fit_choice\n\u001b[0;32m    141\u001b[0m )\n\u001b[0;32m    143\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mloss: \u001b[39m\u001b[39m{\u001b[39;00mresults[\u001b[39m0\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m, accuracy: \u001b[39m\u001b[39m{\u001b[39;00mresults[\u001b[39m1\u001b[39m]\u001b[39m*\u001b[39m\u001b[39m100\u001b[39m\u001b[39m:\u001b[39;00m\u001b[39m .2f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m%\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    145\u001b[0m \u001b[39m# we add a target_type_ attribute to our model so yellowbrick knows how to make the visualizations\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\prime\\OneDrive\\Documents\\CMU\\research\\TrafficFlowForecasting\\prototype\\Quick\\runners\\utils.py:193\u001b[0m, in \u001b[0;36mrun_model\u001b[1;34m(name, learner, epochs, no_bar, lr_choice, fit_choice, lr_funcs)\u001b[0m\n\u001b[0;32m    188\u001b[0m lr_choice: \u001b[39mint\u001b[39m \u001b[39m=\u001b[39m LEARNING_RATE_OPTIONS[lr_choice]\n\u001b[0;32m    191\u001b[0m \u001b[39mwith\u001b[39;00m learner\u001b[39m.\u001b[39mno_bar() \u001b[39mif\u001b[39;00m no_bar \u001b[39melse\u001b[39;00m contextlib\u001b[39m.\u001b[39mExitStack() \u001b[39mas\u001b[39;00m gs:\n\u001b[1;32m--> 193\u001b[0m     lr \u001b[39m=\u001b[39m learner\u001b[39m.\u001b[39;49mlr_find(suggest_funcs\u001b[39m=\u001b[39;49mlr_funcs)\n\u001b[0;32m    195\u001b[0m         \u001b[39m# fitting functions, they give different results, some networks perform better with different learning schedule during fitting\u001b[39;00m\n\u001b[0;32m    196\u001b[0m     \u001b[39mif\u001b[39;00m(fit_choice \u001b[39m==\u001b[39m FIT):\n",
      "File \u001b[1;32mc:\\Users\\prime\\anaconda3\\envs\\DL\\lib\\site-packages\\fastai\\callback\\schedule.py:304\u001b[0m, in \u001b[0;36mlr_find\u001b[1;34m(self, start_lr, end_lr, num_it, stop_div, show_plot, suggest_funcs)\u001b[0m\n\u001b[0;32m    302\u001b[0m \u001b[39mfor\u001b[39;00m func \u001b[39min\u001b[39;00m tuplify(suggest_funcs):\n\u001b[0;32m    303\u001b[0m     nms\u001b[39m.\u001b[39mappend(func\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(func, partial) \u001b[39melse\u001b[39;00m func\u001b[39m.\u001b[39mfunc\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m) \u001b[39m# deal with partials\u001b[39;00m\n\u001b[1;32m--> 304\u001b[0m     _suggestions\u001b[39m.\u001b[39mappend(func(lrs, losses, num_it))\n\u001b[0;32m    306\u001b[0m SuggestedLRs \u001b[39m=\u001b[39m collections\u001b[39m.\u001b[39mnamedtuple(\u001b[39m'\u001b[39m\u001b[39mSuggestedLRs\u001b[39m\u001b[39m'\u001b[39m, nms)\n\u001b[0;32m    307\u001b[0m lrs, pnts \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\prime\\anaconda3\\envs\\DL\\lib\\site-packages\\fastai\\callback\\schedule.py:231\u001b[0m, in \u001b[0;36mvalley\u001b[1;34m(lrs, losses, num_it)\u001b[0m\n\u001b[0;32m    228\u001b[0m sections \u001b[39m=\u001b[39m (max_end \u001b[39m-\u001b[39m max_start) \u001b[39m/\u001b[39m \u001b[39m3\u001b[39m\n\u001b[0;32m    229\u001b[0m idx \u001b[39m=\u001b[39m max_start \u001b[39m+\u001b[39m \u001b[39mint\u001b[39m(sections) \u001b[39m+\u001b[39m \u001b[39mint\u001b[39m(sections\u001b[39m/\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[1;32m--> 231\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mfloat\u001b[39m(lrs[idx]), (\u001b[39mfloat\u001b[39m(lrs[idx]), losses[idx])\n",
      "\u001b[1;31mIndexError\u001b[0m: index 0 is out of bounds for dimension 0 with size 0"
     ]
    }
   ],
   "source": [
    "results_flow_transformer_1 = run_torch_nn_experiment(\n",
    "    df, \n",
    "    scenario, \n",
    "    'label', \n",
    "    FlowTransformer, \n",
    "    config = {\n",
    "        'feature_groups': feature_groups,\n",
    "        'activation': nn.ReLU(),\n",
    "        'verbose': True,\n",
    "        'embeddings': {\n",
    "            'embedding_size': 128,\n",
    "            'use_rff': True,\n",
    "            'rff_dim': 128,\n",
    "            'rff_std': .5,\n",
    "            'learnable_rff_std': True,\n",
    "        },\n",
    "        'encoder':{\n",
    "            'layers': 2,\n",
    "            'heads': 4,\n",
    "            'forward_expansion': 2,\n",
    "            'pre_norm': False,\n",
    "            'dropout': 0.0,\n",
    "        },\n",
    "        'aggregation': {\n",
    "            'type': 'LSTM',\n",
    "            'layers': 1,\n",
    "        },\n",
    "        'classification_head': {\n",
    "            'layers': 2,\n",
    "            'hidden_size': 64,\n",
    "            'batch_norm': False,\n",
    "            'activation': nn.ReLU(),\n",
    "        }\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
